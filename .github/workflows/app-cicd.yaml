
name: Azodha CI-CD Pipeline

on:
  push:
    branches: [ dev ]
  workflow_dispatch:

jobs:
  build-test-scan-deploy:
    runs-on: ubuntu-latest

    env:
      IMAGE_NAME: amoldevakate2026/azodha.run.place
      IMAGE_TAG: ${{ github.sha }}
      AWS_REGION: us-east-1
      CLUSTER_NAME: EKS_CLOUD
      NAMESPACE: azodha-dev
      DEPLOYMENT_NAME: project-azodha
      CONTAINER_NAME: project-azodha

    steps:
      - name: Checkout source code
        uses: actions/checkout@v4

      # --- Python setup + tests ---
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies and run unit tests
        run: |
          python -m pip install --upgrade pip
          pip install -r app/requirements.txt
          pytest app/

      # --- SonarQube scan ---
      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@v2
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      # --- Docker login ---
      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}

      # --- Build docker image ---
      - name: Build Docker image
        run: |
          docker build -t $IMAGE_NAME:$IMAGE_TAG .
          docker tag $IMAGE_NAME:$IMAGE_TAG $IMAGE_NAME:latest

      # --- Trivy scan ---
      - name: Trivy Image Scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}
          format: table
          severity: CRITICAL,HIGH
          exit-code: 1

      # --- Push docker image ---
      - name: Push Docker image
        run: |
          docker push $IMAGE_NAME:$IMAGE_TAG
          docker push $IMAGE_NAME:latest

      # --- AWS credentials ---
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # --- kubectl install ---
      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      # --- Deploy to EKS ---
      - name: Deploy to EKS
        run: |
          aws eks update-kubeconfig --name $CLUSTER_NAME --region $AWS_REGION

          # Ensure namespace exists
          kubectl apply -f k8s/namespace.yaml

          # Storage (PVC)
          kubectl apply -f k8s/pvc.yaml -n $NAMESPACE

          # OpenTelemetry
          kubectl apply -f k8s/otel.yaml -n $NAMESPACE

          # App + service
          kubectl apply -f k8s/deployment.yaml -n $NAMESPACE
          kubectl apply -f k8s/service.yaml -n $NAMESPACE

          # Update the image to current SHA (no sed required)
          kubectl set image deployment/$DEPLOYMENT_NAME \
            $CONTAINER_NAME=$IMAGE_NAME:$IMAGE_TAG \
            -n $NAMESPACE

          # Autoscaler + Ingress
          kubectl apply -f k8s/HorizontalPodAutoscaler.yaml -n $NAMESPACE
          kubectl apply -f k8s/ingress.yaml -n $NAMESPACE

          kubectl rollout status deployment/$DEPLOYMENT_NAME -n $NAMESPACE
          kubectl get all -n $NAMESPACE
          kubectl get ingress -n $NAMESPACE
          kubectl get hpa -n $NAMESPACE

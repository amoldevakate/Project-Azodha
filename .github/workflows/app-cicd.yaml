
name: Azodha CI-CD Pipeline

on:
  push:
    branches: [ dev ]
  workflow_dispatch:

# Prevent overlapping deployments on quick successive pushes
concurrency:
  group: azodha-dev-deploy
  cancel-in-progress: true

jobs:
  build-test-scan-deploy:
    runs-on: ubuntu-latest

    env:
      IMAGE_NAME: amoldevakate2026/azodha.run.place
      IMAGE_TAG: ${{ github.sha }}
      AWS_REGION: us-east-1
      CLUSTER_NAME: EKS_CLOUD
      NAMESPACE: azodha-dev
      DEPLOYMENT_NAME: project-azodha
      CONTAINER_NAME: project-azodha

    steps:
      # ------------------------------------------------
      # 1) Checkout
      # ------------------------------------------------
      - name: Checkout source code
        uses: actions/checkout@v4

      # ------------------------------------------------
      # 2) Python Setup + Unit Tests
      # ------------------------------------------------
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies and run unit tests
        run: |
          set -euxo pipefail
          python -m pip install --upgrade pip
          pip install -r app/requirements.txt
          pytest app/

      # ------------------------------------------------
      # 3) SonarQube Scan
      # ------------------------------------------------
      - name: SonarQube Scan
        uses: sonarsource/sonarqube-scan-action@v2
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      # ------------------------------------------------
      # 4) Docker Login
      # ------------------------------------------------
      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}

      # ------------------------------------------------
      # 5) Build Docker Image
      # ------------------------------------------------
      - name: Build Docker image
        run: |
          set -euxo pipefail
          docker build -t $IMAGE_NAME:$IMAGE_TAG .
          docker tag $IMAGE_NAME:$IMAGE_TAG $IMAGE_NAME:latest

      # ------------------------------------------------
      # 6) Trivy Image Scan (fail build on HIGH/CRITICAL)
      # ------------------------------------------------
      - name: Trivy Image Scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}
          format: table
          severity: CRITICAL,HIGH
          exit-code: 1

      # ------------------------------------------------
      # 7) Push Docker Image
      # ------------------------------------------------
      - name: Push Docker image
        run: |
          set -euxo pipefail
          docker push $IMAGE_NAME:$IMAGE_TAG
          docker push $IMAGE_NAME:latest

      # ------------------------------------------------
      # 8) Configure AWS Credentials
      # ------------------------------------------------
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # ------------------------------------------------
      # 9) Install kubectl
      # ------------------------------------------------
      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: v1.29.0

      # ------------------------------------------------
      # 10) Deploy to EKS
      # ------------------------------------------------
      - name: Deploy to EKS
        run: |
          set -euxo pipefail

          aws eks update-kubeconfig --name "$CLUSTER_NAME" --region "$AWS_REGION"

          # ---------- Apply manifests (correct order) ----------

          # Namespace (cluster-scoped)
          kubectl apply -f k8s/namespace.yaml

          # Storage
          kubectl apply -n "$NAMESPACE" -f k8s/pvc.yaml

          # OpenTelemetry (make sure these files exist in repo)
          kubectl apply -n "$NAMESPACE" -f k8s/otel.yaml

          # App + Service
          kubectl apply -n "$NAMESPACE" -f k8s/deployment.yaml
          kubectl apply -n "$NAMESPACE" -f k8s/service.yaml

          # Update deployment image to current SHA (no sed)
          kubectl set image -n "$NAMESPACE" deployment/"$DEPLOYMENT_NAME" \
            "$CONTAINER_NAME"="$IMAGE_NAME:$IMAGE_TAG"

          # HPA
          kubectl apply -n "$NAMESPACE" -f k8s/HorizontalPodAutoscaler.yaml

          # Ingress - debug + validate before apply (prevents "name may not be empty")
          echo "----- k8s/ingress.yaml -----"
          cat k8s/ingress.yaml
          echo "----------------------------"

          kubectl apply --dry-run=client -f k8s/ingress.yaml -o yaml
          kubectl apply -n "$NAMESPACE" -f k8s/ingress.yaml

          # ---------- Verification ----------
          kubectl rollout status -n "$NAMESPACE" deployment/"$DEPLOYMENT_NAME"
          kubectl get all -n "$NAMESPACE"
          kubectl get ingress -n "$NAMESPACE"
          kubectl get hpa -n "$NAMESPACE"
